{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check if there is processed data\n",
    "# checkProcessedIfExist()\n",
    "# process and save all data\n",
    "# processAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import plottingdata\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import linecache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting variables\n",
    "dataPath = \"/Users/tulakan/OneDrive/BME/Rehabilitation Project/EMG data/EMG Gyro 22-23 Jul 2015\"  # raw data dir\n",
    "subjectName = \"*\"  # * for all\n",
    "processedFolderName = \"Processed\"\n",
    "processedPath = os.path.join(dataPath, processedFolderName, subjectName)  # processed data dir\n",
    "printSubjtName = False\n",
    "printDataFileNameFor = \"no\"  # name of subject to print\n",
    "windowSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loop through directory -> get folder name for each subject and raw data file names\n",
    "allSubject = [x for x in os.listdir(dataPath) if not x.startswith(\".\") and x != processedFolderName]\n",
    "if printSubjtName: print allSubject\n",
    "\n",
    "# data file names for each subject is collected as dictionary\n",
    "dataFileName = {x: [i for i in os.listdir(os.path.join(dataPath, x)) if not i.startswith(\".\") and i.endswith(\".ASC\")]  for x in allSubject}\n",
    "if printDataFileName != \"no\":\n",
    "    try:\n",
    "        print dataFileName[printDataFileName]\n",
    "    except KeyError:\n",
    "        print \"No data for\", printDataFileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to call\n",
    "def checkProcessedIfExist():\n",
    "    if not os.path.exists(os.path.join(dataPath, \"Processed\")):\n",
    "        os.makedirs(os.path.join(dataPath, \"Processed\"))\n",
    "    for x in allSubject:\n",
    "        if not os.path.exists(os.path.join(dataPath, \"Processed\", x)):\n",
    "            os.makedirs(os.path.join(dataPath, \"Processed\", x))\n",
    "    for x in allSubject:\n",
    "        # .p is pickle files for processed data\n",
    "        # this snippet trying to find .p in processed folder\n",
    "        # if found it shows files name\n",
    "        # else print no .p file in current dir\n",
    "        if len([i for i in os.listdir(os.path.join(dataPath, processedFolderName, x)) if i.endswith(\".p\")]) == 0:\n",
    "            print \"no .p file in\", os.path.join(dataPath, processedFolderName, x)\n",
    "        else:\n",
    "            print x, \":\", [i for i in os.listdir(os.path.join(dataPath, processedFolderName, x)) if i.endswith(\".p\")]\n",
    "        # for y in dataFileName[x]:\n",
    "        # if not os.path.exists(os.path.join(dataPath, processedFolderName, x, y.split(\".\")[0]+\"_processed.p\")):\n",
    "        #     print y.split(\".\")[0]+\"_processed.p\", \"does not exist..\"\n",
    "        # print os.path.join(dataPath, allSubject[0], dataFileName[allSubject[0]][0])\n",
    "\n",
    "\n",
    "def processAll():\n",
    "    # process data\n",
    "    savePath = os.path.join(dataPath, processedFolderName)\n",
    "    # count time\n",
    "    startTime = datetime.datetime.now()\n",
    "\n",
    "    for i in allSubject:\n",
    "        savedir = os.path.join(savePath, i)\n",
    "        print \"#########################\"\n",
    "        print \"processing\", i + \"...\"\n",
    "        print \"#########################\"\n",
    "        for j in dataFileName[i]:\n",
    "            saveProcessed(os.path.join(dataPath, i, j), savedir, windowSize)\n",
    "            print \"#########################\"\n",
    "            print j, \"process - DONE\"\n",
    "            print \"#########################\"\n",
    "\n",
    "    # savedir = os.path.join(savePath, allSubject[0])\n",
    "    # processData.saveProcessed(os.path.join(dataPath, allSubject[0], dataFileName[allSubject[0]][0]), savedir, windowSize)\n",
    "\n",
    "    # count time\n",
    "    stopTime = datetime.datetime.now()\n",
    "    print \"data processing takes\", stopTime-startTime\n",
    "\n",
    "\n",
    "def saveProcessed(filename, savedir, windowSize):\n",
    "    # filename = motorSpeed+actionPlane+'.ASC'\n",
    "    filenameSplit = (os.path.split(filename)[-1]).split(\".\")[0]\n",
    "    # actionname = os.path.split(filename)[-1]  # screen dir out, only pick file name\n",
    "    # print filenameSplit\n",
    "\n",
    "    # get sampling rate\n",
    "    print \"get sampling rate..\"\n",
    "    spr = linecache.getline(filename, 1)\n",
    "    spr = spr.split()[0]\n",
    "    print \"DONE\"\n",
    "    # print spr\n",
    "    # get header\n",
    "    print \"get header..\"\n",
    "    header = linecache.getline(filename, 3)\n",
    "    header = getHeader(header)\n",
    "    print \"DONE\"\n",
    "    # print header\n",
    "    time.sleep(1)\n",
    "    # get raw data\n",
    "    print \"get raw data..\"\n",
    "    rawdt = np.loadtxt(filename, skiprows=3)\n",
    "    fstcoldt = rawdt[:, 0]  # first column data 1,2,3,...,len(data)\n",
    "    fstcoldtassec = fstcoldt/int(spr)  # convert hertz to sec\n",
    "    rawdt = rawdt[:, 1:]  # 10 channels of muscles\n",
    "    print \"DONE\"\n",
    "\n",
    "    # process data\n",
    "    fstcoldtassec = fstcoldtassec[0:-1-windowSize+1]  # cutting out the window size\n",
    "    print \"rectify data..\"\n",
    "    rawrecdt = abs(rawdt)  # raw data rectification\n",
    "    print \"DONE\"\n",
    "    print \"applying moving average filter..\"\n",
    "    mavgdt = movingAvgFilter(windowSize, rawrecdt)  # moving average filtered\n",
    "    print \"DONE\"\n",
    "    print \"applying root mean square filter..\"\n",
    "    rmsdt = rmsFilter(windowSize, rawrecdt)  # root mean square filted\n",
    "    print \"DONE\"\n",
    "    rawrecdt = rawrecdt[0+(windowSize/2):-1-(windowSize/2)+1, :]  # make easier to plot\n",
    "\n",
    "    # save data\n",
    "    # savedir = os.path.join(subjectName, 'processed')\n",
    "    # if not os.path.exists(savedir):\n",
    "    #     os.makedirs(savedir)\n",
    "    print \"dump filtered data to pickle files..\"\n",
    "    cPickle.dump(header, open(os.path.join(savedir, 'header.p'), \"wb\"))\n",
    "    cPickle.dump(fstcoldtassec, open(os.path.join(savedir, 'fstcoldtassec.p'), \"wb\"))\n",
    "    cPickle.dump(rawrecdt, open(os.path.join(savedir, filenameSplit + \"_\" + str(windowSize) + \"_rectify.p\"), \"wb\"))\n",
    "    print \"rectify DONE\"\n",
    "    cPickle.dump(mavgdt, open(os.path.join(savedir, filenameSplit + \"_\" + str(windowSize) + \"_mAvg.p\"), \"wb\"))\n",
    "    print \"moving average DONE\"\n",
    "    cPickle.dump(rmsdt, open(os.path.join(savedir, filenameSplit + \"_\" + str(windowSize) + \"_rms.p\"), \"wb\"))\n",
    "    print \"root mean square DONE\"\n",
    "    # np.savetxt(savedir+'//'+subjectName+'_'+actionname+'_'+str(windowSize)+'_'+'rectify'+'.txt', rawrecdt)\n",
    "    # np.savetxt(savedir+'//'+subjectName+'_'+actionname+'_'+str(windowSize)+'_'+'mAvg'+'.txt', mavgdt)\n",
    "    # np.savetxt(savedir+'//'+subjectName+'_'+actionname+'_'+str(windowSize)+'_'+'rms'+'.txt', rmsdt)\n",
    "\n",
    "\n",
    "# filter functions\n",
    "\n",
    "# These filters will move window over data starting at data position of (window size/2)\n",
    "# so that data loss will be divided to be half for initial and half for terminal\n",
    "\n",
    "def movingAvgFilter(windowSize, data):\n",
    "    startPoint = windowSize/2  # position to start windowing\n",
    "    noOfData = np.size(data, 0)\n",
    "    dataCol = np.size(data, 1)\n",
    "\n",
    "    newData = np.zeros((noOfData-windowSize, dataCol))  # -1 to ignore data[:,1]\n",
    "    for i in range(startPoint, noOfData-startPoint):\n",
    "        newData[i-startPoint, :] = (sum(data[i-startPoint:i+startPoint, :]))/windowSize\n",
    "    return newData\n",
    "\n",
    "\n",
    "def rmsFilter(windowSize, data):\n",
    "    startPoint = windowSize/2  # position to start windowing\n",
    "    noOfData = np.size(data, 0)\n",
    "    dataCol = np.size(data, 1)\n",
    "\n",
    "    newData = np.zeros((noOfData-windowSize, dataCol))  # -1 to ignore data[:,1]\n",
    "    for i in range(startPoint, noOfData-startPoint):\n",
    "        newData[i-startPoint, :] = np.sqrt(sum(data[i-startPoint:i+startPoint, :]**2))/np.sqrt(windowSize)\n",
    "    return newData\n",
    "\n",
    "\n",
    "# get data\n",
    "def getHeader(rawHeader):\n",
    "    ##### header manipulation\n",
    "    splited = rawHeader.split()  # split header\n",
    "    jointNo = 3  # number of obj to join\n",
    "    loopNo = len(splited)/jointNo  # number of obj after join\n",
    "    finalHeader = [splited[0]]  # pre-allocation\n",
    "\n",
    "    for i in range(loopNo):\n",
    "        finalHeader.append(splited[(3*i)+1]+splited[(3*i)+2]+splited[(3*i)+3])  # rearrange header\n",
    "\n",
    "    return finalHeader\n",
    "\n",
    "\n",
    "def getDataBack(savedir, subjectName, actionname, windowSize, filterType):\n",
    "    header = cPickle.load(open(os.path.join(savedir, 'header.p'), \"rb\"))\n",
    "    fstcoldtassec = cPickle.load(open(os.path.join(savedir, actionname+'_'+'fstcoldtassec.p'), \"rb\"))\n",
    "    data = np.loadtxt(savedir+'//'+subjectName+'_'+actionname+'_'+str(windowSize)+'_'+filterType+'.txt')\n",
    "\n",
    "    return header, fstcoldtassec, data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

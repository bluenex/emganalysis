{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_aon = figure(plot_width=800, plot_height=400)\n",
    "plt_aon.line(range(np.size(both_aon_64_mAvg[both_aon_64_mAvg.keys()[0]])), both_aon_64_mAvg[both_aon_64_mAvg.keys()[3]], line_width=1)\n",
    "\n",
    "show(plt_aon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.figure(figsize=(100,15))\n",
    "    plt.plot(both_aon_64_mAvg[both_aon_64_mAvg.keys()[i]])\n",
    "# plt.figure(figsize=(100,15))\n",
    "# plt.plot(both_aon_64_mAvg[both_aon_64_mAvg.keys()[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in aon.keys(): print aon.keys().index(a), a, np.size(aon[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.shape(aon[aon.keys()[0][11]])\n",
    "# np.shape([[1,2,3],[4,6,7]])\n",
    "print np.shape(aon[aon.keys()[0]][:0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "subjectName = \"Aon\"\n",
    "loadPath = os.path.join(dataPath, processedFolderName, subjectName) # path to load data\n",
    "\n",
    "# for x in [i for i in os.listdir(loadPath) if not i.startswith(\".\")]:\n",
    "#     print x\n",
    "    \n",
    "x = [i for i in os.listdir(loadPath) if not i.startswith(\".\")]\n",
    "# print x\n",
    "\n",
    "def getheader(path):\n",
    "    print \"getting header for\", subjectName + \"..\"\n",
    "    header = cPickle.load(open((os.path.join(path, \"header.p\")), \"rb\"))\n",
    "    header = header[1:len(header)]\n",
    "    return header\n",
    "    \n",
    "def getdata(filename):\n",
    "    print \"getting\", filename, \"data...\"\n",
    "    return cPickle.load(open((os.path.join(loadPath, filename)), \"rb\"))\n",
    "        \n",
    "header = getheader(loadPath)\n",
    "temp = getdata(x[0])\n",
    "# aon = {i:getdata(i) for i in x}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.shape(temp)[1]\n",
    "both_aon_64_mAvg = {i:temp[:,header.index(i)] for i in header}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.size(both_aon_64_mAvg[both_aon_64_mAvg.keys()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check if there is processed data\n",
    "# checkProcessedIfExist()\n",
    "# process and save all data\n",
    "# processAll(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# ----------\n",
    "# run this cell and all below first\n",
    "# ----------\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import plottingdata\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import linecache\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting variables\n",
    "dataPath = \"/Users/tulakan/OneDrive/BME/Rehabilitation Project/EMG data/EMG Gyro 22-23 Jul 2015\"  # raw data dir\n",
    "processedFolderName = \"Processed\"\n",
    "savePath = os.path.join(dataPath, processedFolderName)\n",
    "printSubjtName = False\n",
    "printDataFileNameFor = \"no\"  # name of subject to print\n",
    "windowSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loop through directory -> get folder name for each subject and raw data file names\n",
    "allSubject = [x for x in os.listdir(dataPath) if not x.startswith(\".\") and x != processedFolderName]\n",
    "if printSubjtName: print allSubject\n",
    "\n",
    "# data file names for each subject is collected as dictionary\n",
    "dataFileName = {x: [i for i in os.listdir(os.path.join(dataPath, x)) if not i.startswith(\".\") and i.endswith(\".ASC\")]  for x in allSubject}\n",
    "if printDataFileNameFor != \"no\":\n",
    "    try:\n",
    "        print dataFileName[printDataFileNameFor]\n",
    "    except KeyError:\n",
    "        print \"No data for\", printDataFileNameFor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to call\n",
    "def checkProcessedIfExist():\n",
    "    if not os.path.exists(os.path.join(dataPath, \"Processed\")):\n",
    "        os.makedirs(os.path.join(dataPath, \"Processed\"))\n",
    "    for x in allSubject:\n",
    "        if not os.path.exists(os.path.join(dataPath, \"Processed\", x)):\n",
    "            os.makedirs(os.path.join(dataPath, \"Processed\", x))\n",
    "    for x in allSubject:\n",
    "        # .p is pickle files for processed data\n",
    "        # this snippet trying to find .p in processed folder\n",
    "        # if found it shows files name\n",
    "        # else print no .p file in current dir\n",
    "        if len([i for i in os.listdir(os.path.join(dataPath, processedFolderName, x)) if i.endswith(\".p\")]) == 0:\n",
    "            print \"no .p file in\", os.path.join(dataPath, processedFolderName, x)\n",
    "        else:\n",
    "            print x, \":\", [i for i in os.listdir(os.path.join(dataPath, processedFolderName, x)) if i.endswith(\".p\")]\n",
    "        # for y in dataFileName[x]:\n",
    "        # if not os.path.exists(os.path.join(dataPath, processedFolderName, x, y.split(\".\")[0]+\"_processed.p\")):\n",
    "        #     print y.split(\".\")[0]+\"_processed.p\", \"does not exist..\"\n",
    "        # print os.path.join(dataPath, allSubject[0], dataFileName[allSubject[0]][0])\n",
    "\n",
    "# process data\n",
    "def processAll(savePath):\n",
    "    # count time\n",
    "    startTime = datetime.datetime.now()\n",
    "\n",
    "    for i in allSubject:\n",
    "        savedir = os.path.join(savePath, i)\n",
    "        print \"#########################\"\n",
    "        print \"processing\", i + \"...\"\n",
    "        print \"#########################\"\n",
    "        for j in dataFileName[i]:\n",
    "            saveProcessed(os.path.join(dataPath, i, j), savedir, windowSize)\n",
    "            print \"#########################\"\n",
    "            print j, \"process - DONE\"\n",
    "            print \"#########################\"\n",
    "\n",
    "    # savedir = os.path.join(savePath, allSubject[0])\n",
    "    # processData.saveProcessed(os.path.join(dataPath, allSubject[0], dataFileName[allSubject[0]][0]), savedir, windowSize)\n",
    "\n",
    "    # count time\n",
    "    stopTime = datetime.datetime.now()\n",
    "    print \"data processing takes\", stopTime-startTime\n",
    "\n",
    "\n",
    "def saveProcessed(filename, savedir, windowSize):\n",
    "    # filename = motorSpeed+actionPlane+'.ASC'\n",
    "    filenameSplit = (os.path.split(filename)[-1]).split(\".\")[0]\n",
    "    # actionname = os.path.split(filename)[-1]  # screen dir out, only pick file name\n",
    "    # print filenameSplit\n",
    "\n",
    "    # get sampling rate\n",
    "    print \"get sampling rate..\"\n",
    "    spr = linecache.getline(filename, 1)\n",
    "    spr = spr.split()[0]\n",
    "    print \"DONE\"\n",
    "    # print spr\n",
    "    # get header\n",
    "    print \"get header..\"\n",
    "    header = linecache.getline(filename, 3)\n",
    "    header = getHeader(header)\n",
    "    print \"DONE\"\n",
    "    # print header\n",
    "    time.sleep(1)\n",
    "    # get raw data\n",
    "    print \"get raw data..\"\n",
    "    rawdt = np.loadtxt(filename, skiprows=3)\n",
    "    fstcoldt = rawdt[:, 0]  # first column data 1,2,3,...,len(data)\n",
    "    fstcoldtassec = fstcoldt/int(spr)  # convert hertz to sec\n",
    "    rawdt = rawdt[:, 1:]  # 10 channels of muscles\n",
    "    print \"DONE\"\n",
    "\n",
    "    # process data\n",
    "    fstcoldtassec = fstcoldtassec[0:-1-windowSize+1]  # cutting out the window size\n",
    "    print \"rectify data..\"\n",
    "    rawrecdt = abs(rawdt)  # raw data rectification\n",
    "    print \"DONE\"\n",
    "    print \"applying moving average filter..\"\n",
    "    mavgdt = movingAvgFilter(windowSize, rawrecdt)  # moving average filtered\n",
    "    print \"DONE\"\n",
    "    print \"applying root mean square filter..\"\n",
    "    rmsdt = rmsFilter(windowSize, rawrecdt)  # root mean square filted\n",
    "    print \"DONE\"\n",
    "    rawrecdt = rawrecdt[0+(windowSize/2):-1-(windowSize/2)+1, :]  # make easier to plot\n",
    "\n",
    "    # save data\n",
    "    # savedir = os.path.join(subjectName, 'processed')\n",
    "    # if not os.path.exists(savedir):\n",
    "    #     os.makedirs(savedir)\n",
    "    print \"dump filtered data to pickle files..\"\n",
    "    cPickle.dump(header, open(os.path.join(savedir, 'header.p'), \"wb\"))\n",
    "    cPickle.dump(fstcoldtassec, open(os.path.join(savedir, 'fstcoldtassec.p'), \"wb\"))\n",
    "    cPickle.dump(rawrecdt, open(os.path.join(savedir, filenameSplit + \"_\" + str(windowSize) + \"_rectify.p\"), \"wb\"))\n",
    "    print \"rectify DONE\"\n",
    "    cPickle.dump(mavgdt, open(os.path.join(savedir, filenameSplit + \"_\" + str(windowSize) + \"_mAvg.p\"), \"wb\"))\n",
    "    print \"moving average DONE\"\n",
    "    cPickle.dump(rmsdt, open(os.path.join(savedir, filenameSplit + \"_\" + str(windowSize) + \"_rms.p\"), \"wb\"))\n",
    "    print \"root mean square DONE\"\n",
    "    # np.savetxt(savedir+'//'+subjectName+'_'+actionname+'_'+str(windowSize)+'_'+'rectify'+'.txt', rawrecdt)\n",
    "    # np.savetxt(savedir+'//'+subjectName+'_'+actionname+'_'+str(windowSize)+'_'+'mAvg'+'.txt', mavgdt)\n",
    "    # np.savetxt(savedir+'//'+subjectName+'_'+actionname+'_'+str(windowSize)+'_'+'rms'+'.txt', rmsdt)\n",
    "\n",
    "\n",
    "# filter functions\n",
    "\n",
    "# These filters will move window over data starting at data position of (window size/2)\n",
    "# so that data loss will be divided to be half for initial and half for terminal\n",
    "\n",
    "def movingAvgFilter(windowSize, data):\n",
    "    startPoint = windowSize/2  # position to start windowing\n",
    "    noOfData = np.size(data, 0)\n",
    "    dataCol = np.size(data, 1)\n",
    "\n",
    "    newData = np.zeros((noOfData-windowSize, dataCol))  # -1 to ignore data[:,1]\n",
    "    for i in range(startPoint, noOfData-startPoint):\n",
    "        newData[i-startPoint, :] = (sum(data[i-startPoint:i+startPoint, :]))/windowSize\n",
    "    return newData\n",
    "\n",
    "\n",
    "def rmsFilter(windowSize, data):\n",
    "    startPoint = windowSize/2  # position to start windowing\n",
    "    noOfData = np.size(data, 0)\n",
    "    dataCol = np.size(data, 1)\n",
    "\n",
    "    newData = np.zeros((noOfData-windowSize, dataCol))  # -1 to ignore data[:,1]\n",
    "    for i in range(startPoint, noOfData-startPoint):\n",
    "        newData[i-startPoint, :] = np.sqrt(sum(data[i-startPoint:i+startPoint, :]**2))/np.sqrt(windowSize)\n",
    "    return newData\n",
    "\n",
    "\n",
    "# get data\n",
    "def getHeader(rawHeader):\n",
    "    ##### header manipulation\n",
    "    splited = rawHeader.split()  # split header\n",
    "    jointNo = 3  # number of obj to join\n",
    "    loopNo = len(splited)/jointNo  # number of obj after join\n",
    "    finalHeader = [splited[0]]  # pre-allocation\n",
    "\n",
    "    for i in range(loopNo):\n",
    "        finalHeader.append(splited[(3*i)+1]+splited[(3*i)+2]+splited[(3*i)+3])  # rearrange header\n",
    "\n",
    "    return finalHeader\n",
    "\n",
    "\n",
    "# def getDataBack(savedir, subjectName, actionname, windowSize, filterType):\n",
    "#     header = cPickle.load(open(os.path.join(savedir, 'header.p'), \"rb\"))\n",
    "#     fstcoldtassec = cPickle.load(open(os.path.join(savedir, actionname+'_'+'fstcoldtassec.p'), \"rb\"))\n",
    "#     data = np.loadtxt(savedir+'//'+subjectName+'_'+actionname+'_'+str(windowSize)+'_'+filterType+'.txt')\n",
    "\n",
    "#     return header, fstcoldtassec, data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
